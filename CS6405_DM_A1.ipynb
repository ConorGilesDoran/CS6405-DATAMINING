{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jNV5YRzUQOp8"
   },
   "source": [
    "# CS3033/CS6405 - Datamining - First Assignment\n",
    "\n",
    "# Part 1 - Data Preparation\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EVaSEvHiUocf"
   },
   "source": [
    "## 1.1. Load the dataset on Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "T57icLiVUUxK"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Siblings/Spouses Aboard</th>\n",
       "      <th>Parents/Children Aboard</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Mr. Owen Harris Braund</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mrs. John Bradley (Florence Briggs Thayer) Cum...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.2833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Miss. Laina Heikkinen</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.9250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mrs. Jacques Heath (Lily May Peel) Futrelle</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Mr. William Henry Allen</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>883</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Rev. Juozas Montvila</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>884</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Miss. Margaret Edith Graham</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>885</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Miss. Catherine Helen Johnston</td>\n",
       "      <td>female</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>23.4500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>886</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mr. Karl Howell Behr</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Mr. Patrick Dooley</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.7500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>887 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "..           ...       ...     ...   \n",
       "882          883         0       2   \n",
       "883          884         1       1   \n",
       "884          885         0       3   \n",
       "885          886         1       1   \n",
       "886          887         0       3   \n",
       "\n",
       "                                                  Name     Sex   Age  \\\n",
       "0                               Mr. Owen Harris Braund    male  22.0   \n",
       "1    Mrs. John Bradley (Florence Briggs Thayer) Cum...  female  38.0   \n",
       "2                                Miss. Laina Heikkinen  female  26.0   \n",
       "3          Mrs. Jacques Heath (Lily May Peel) Futrelle  female  35.0   \n",
       "4                              Mr. William Henry Allen    male  35.0   \n",
       "..                                                 ...     ...   ...   \n",
       "882                               Rev. Juozas Montvila    male  27.0   \n",
       "883                        Miss. Margaret Edith Graham  female  19.0   \n",
       "884                     Miss. Catherine Helen Johnston  female   7.0   \n",
       "885                               Mr. Karl Howell Behr    male  26.0   \n",
       "886                                 Mr. Patrick Dooley    male  32.0   \n",
       "\n",
       "     Siblings/Spouses Aboard  Parents/Children Aboard     Fare  \n",
       "0                          1                      0.0   7.2500  \n",
       "1                          1                      0.0  71.2833  \n",
       "2                          0                      0.0   7.9250  \n",
       "3                          1                      NaN  53.1000  \n",
       "4                          0                      0.0   8.0500  \n",
       "..                       ...                      ...      ...  \n",
       "882                        0                      0.0  13.0000  \n",
       "883                        0                      0.0  30.0000  \n",
       "884                        1                      2.0  23.4500  \n",
       "885                        0                      0.0  30.0000  \n",
       "886                        0                      0.0   7.7500  \n",
       "\n",
       "[887 rows x 9 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Reading in the file \n",
    "titanic = pd.read_csv(\"https://github.com/andvise/DataAnalyticsDatasets/blob/16ca8de1233c8643bfe85fcd1cd87c9ff2221312/titanic.csv?raw=True\")\n",
    "\n",
    "# Taking a look at the dataframe\n",
    "titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8k2he0ePUW_p"
   },
   "source": [
    "\n",
    "## 1.2. Display the attributes' name and their data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "JKJ6MFXCQs9I"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId                  int64\n",
       "Survived                     int64\n",
       "Pclass                       int64\n",
       "Name                        object\n",
       "Sex                         object\n",
       "Age                        float64\n",
       "Siblings/Spouses Aboard      int64\n",
       "Parents/Children Aboard    float64\n",
       "Fare                       float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Most attributes are either of type 'int64' or 'float64' \n",
    "titanic.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "omD5VBUSU6wR"
   },
   "source": [
    "## 1.3. Delete the columns PassengerId and Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ldx_7Y5uVm9e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Siblings/Spouses Aboard</th>\n",
       "      <th>Parents/Children Aboard</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.2833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.9250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>23.4500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.7500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>887 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass     Sex   Age  Siblings/Spouses Aboard  \\\n",
       "0           0       3    male  22.0                        1   \n",
       "1           1       1  female  38.0                        1   \n",
       "2           1       3  female  26.0                        0   \n",
       "3           1       1  female  35.0                        1   \n",
       "4           0       3    male  35.0                        0   \n",
       "..        ...     ...     ...   ...                      ...   \n",
       "882         0       2    male  27.0                        0   \n",
       "883         1       1  female  19.0                        0   \n",
       "884         0       3  female   7.0                        1   \n",
       "885         1       1    male  26.0                        0   \n",
       "886         0       3    male  32.0                        0   \n",
       "\n",
       "     Parents/Children Aboard     Fare  \n",
       "0                        0.0   7.2500  \n",
       "1                        0.0  71.2833  \n",
       "2                        0.0   7.9250  \n",
       "3                        NaN  53.1000  \n",
       "4                        0.0   8.0500  \n",
       "..                       ...      ...  \n",
       "882                      0.0  13.0000  \n",
       "883                      0.0  30.0000  \n",
       "884                      2.0  23.4500  \n",
       "885                      0.0  30.0000  \n",
       "886                      0.0   7.7500  \n",
       "\n",
       "[887 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Can remove these columns using the dataframe.drop() function from pandas\n",
    "titanic = titanic.drop(columns = ['PassengerId', 'Name'])\n",
    "\n",
    "titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-L7t0L9RU69P"
   },
   "source": [
    "## 1.4. Replace all missing values with 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "XxUpIQwjXRbA"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived                   0\n",
       "Pclass                     0\n",
       "Sex                        0\n",
       "Age                        0\n",
       "Siblings/Spouses Aboard    0\n",
       "Parents/Children Aboard    1\n",
       "Fare                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First check and see what attributes contain missing data\n",
    "titanic.isnull().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Vcye6JIyVnde"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived                   0\n",
       "Pclass                     0\n",
       "Sex                        0\n",
       "Age                        0\n",
       "Siblings/Spouses Aboard    0\n",
       "Parents/Children Aboard    0\n",
       "Fare                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Missing values can be set to 0 using the dataframe.fillna() function\n",
    "titanic = titanic.fillna(0)\n",
    "\n",
    "# Now there is no missing data\n",
    "titanic.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DSv6MK68U6_y"
   },
   "source": [
    "## 1.5. Transform the Sex column into a numerical one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Q2MVD4PCaLMe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        male\n",
       "1      female\n",
       "2      female\n",
       "3      female\n",
       "4        male\n",
       "        ...  \n",
       "882      male\n",
       "883    female\n",
       "884    female\n",
       "885      male\n",
       "886      male\n",
       "Name: Sex, Length: 887, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Taking a look at the data in this attribute column:\n",
    "titanic.Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Ehv_mGnSVoCF"
   },
   "outputs": [],
   "source": [
    "# The Sex column data can be transformed to numerical data using pd.factorize()\n",
    "# [0] specifies first part of .factorize() output (numerical data)\n",
    "titanic.Sex = pd.factorize(titanic.Sex)[0]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "-uz4gmSYaI4O"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      1\n",
       "2      1\n",
       "3      1\n",
       "4      0\n",
       "      ..\n",
       "882    0\n",
       "883    1\n",
       "884    1\n",
       "885    0\n",
       "886    0\n",
       "Name: Sex, Length: 887, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Taking another look at the data in this attribute column\n",
    "# male = 0 and female = 1\n",
    "titanic.Sex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B1VUQPZKU7CD"
   },
   "source": [
    "\n",
    "## 1.6. Use Survived as the target label and the rest of the data frame as features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x7L3qTvyYJVm"
   },
   "source": [
    "Before dividing up the dataset, the data must first be shuffled randomly. This means that row indexes are no longer ordered from 0 to 887, but now have a random row order. This preprocessing step is performed in order to avoid potential biases that may have been introduced from the collection of data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Q6c-MxrUYDwA"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Siblings/Spouses Aboard</th>\n",
       "      <th>Parents/Children Aboard</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.1750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>113.2750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.9250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.8958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.3875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.7750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>887 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass  Sex   Age  Siblings/Spouses Aboard  \\\n",
       "91          0       1    0  46.0                        1   \n",
       "656         0       1    0  58.0                        0   \n",
       "184         0       1    0  39.0                        0   \n",
       "44          0       3    0  30.0                        0   \n",
       "2           1       3    1  26.0                        0   \n",
       "..        ...     ...  ...   ...                      ...   \n",
       "60          1       1    1  38.0                        0   \n",
       "222         0       3    0  22.0                        0   \n",
       "569         1       1    0  36.0                        0   \n",
       "424         1       2    1  19.0                        0   \n",
       "106         1       3    0  29.0                        0   \n",
       "\n",
       "     Parents/Children Aboard      Fare  \n",
       "91                       0.0   61.1750  \n",
       "656                      2.0  113.2750  \n",
       "184                      0.0   50.0000  \n",
       "44                       0.0    8.0500  \n",
       "2                        0.0    7.9250  \n",
       "..                       ...       ...  \n",
       "60                       0.0   80.0000  \n",
       "222                      0.0    7.8958  \n",
       "569                      0.0   26.3875  \n",
       "424                      0.0   26.0000  \n",
       "106                      0.0    7.7750  \n",
       "\n",
       "[887 rows x 7 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffling the data - frac = 1 ensures the whole df is shuffled.\n",
    "titanic = titanic.sample(frac = 1)\n",
    "\n",
    "# the order of rows has now been randomized\n",
    "titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Fp_o4HuOVome"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91     0\n",
       "656    0\n",
       "184    0\n",
       "44     0\n",
       "2      1\n",
       "      ..\n",
       "60     1\n",
       "222    0\n",
       "569    1\n",
       "424    1\n",
       "106    1\n",
       "Name: Survived, Length: 887, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assigning Survived column as the target label\n",
    "target_lab =  titanic.Survived\n",
    "\n",
    "# 0 = not survived, 1 = survived\n",
    "target_lab "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "R-KnYnCvRdhJ"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Siblings/Spouses Aboard</th>\n",
       "      <th>Parents/Children Aboard</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.1750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>113.2750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.9250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.8958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.3875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.7750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>887 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass  Sex   Age  Siblings/Spouses Aboard  Parents/Children Aboard  \\\n",
       "91        1    0  46.0                        1                      0.0   \n",
       "656       1    0  58.0                        0                      2.0   \n",
       "184       1    0  39.0                        0                      0.0   \n",
       "44        3    0  30.0                        0                      0.0   \n",
       "2         3    1  26.0                        0                      0.0   \n",
       "..      ...  ...   ...                      ...                      ...   \n",
       "60        1    1  38.0                        0                      0.0   \n",
       "222       3    0  22.0                        0                      0.0   \n",
       "569       1    0  36.0                        0                      0.0   \n",
       "424       2    1  19.0                        0                      0.0   \n",
       "106       3    0  29.0                        0                      0.0   \n",
       "\n",
       "         Fare  \n",
       "91    61.1750  \n",
       "656  113.2750  \n",
       "184   50.0000  \n",
       "44     8.0500  \n",
       "2      7.9250  \n",
       "..        ...  \n",
       "60    80.0000  \n",
       "222    7.8958  \n",
       "569   26.3875  \n",
       "424   26.0000  \n",
       "106    7.7750  \n",
       "\n",
       "[887 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assigning the columns from PClass onwards as the features data\n",
    "features = titanic.loc[:,\"Pclass\":]\n",
    "\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "agtpqpdUU7FP"
   },
   "source": [
    "## 1.7. Divide your dataset in 80% for training and 20% for test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J9kwRQVc-QC-"
   },
   "source": [
    "Now the data can be split into training and test subsets.\n",
    "\n",
    "80% of the feature and label data is assigned to training and 20% is assigned to testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "c3XiVPyoVpDp"
   },
   "outputs": [],
   "source": [
    "# As 887 does not split evenly into 80/20 subsets, the cutoff value is rounded to the nearest whole value\n",
    "# 709.6 -> 710\n",
    "cutoff = round(len(titanic)*0.8) \n",
    "\n",
    "# ~80% of the data (710 rows)\n",
    "train_features = features.iloc[:cutoff,]\n",
    "train_labels = target_lab.iloc[:cutoff,]\n",
    "\n",
    "# ~20% of data (177 rows)\n",
    "test_features = features.iloc[cutoff:,]  \n",
    "test_labels = target_lab.iloc[cutoff:,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "utcznOupodw7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Siblings/Spouses Aboard</th>\n",
       "      <th>Parents/Children Aboard</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.1750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>113.2750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.9250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.2292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>710 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass  Sex   Age  Siblings/Spouses Aboard  Parents/Children Aboard  \\\n",
       "91        1    0  46.0                        1                      0.0   \n",
       "656       1    0  58.0                        0                      2.0   \n",
       "184       1    0  39.0                        0                      0.0   \n",
       "44        3    0  30.0                        0                      0.0   \n",
       "2         3    1  26.0                        0                      0.0   \n",
       "..      ...  ...   ...                      ...                      ...   \n",
       "438       3    0  20.0                        0                      0.0   \n",
       "585       3    0  22.0                        0                      0.0   \n",
       "580       1    0  36.0                        0                      0.0   \n",
       "36        3    0  18.0                        0                      0.0   \n",
       "730       2    0  23.0                        0                      0.0   \n",
       "\n",
       "         Fare  \n",
       "91    61.1750  \n",
       "656  113.2750  \n",
       "184   50.0000  \n",
       "44     8.0500  \n",
       "2      7.9250  \n",
       "..        ...  \n",
       "438    9.5000  \n",
       "585    8.0500  \n",
       "580   40.1250  \n",
       "36     7.2292  \n",
       "730   13.0000  \n",
       "\n",
       "[710 rows x 6 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Taking a look at the training features dataset (80% of original)\n",
    "# Note that the indexes are still in the random order as before\n",
    "train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "iRF4gRlKXwtc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Siblings/Spouses Aboard</th>\n",
       "      <th>Parents/Children Aboard</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.7500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>49.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.9292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>151.5500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>55.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>17.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.8958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>36.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.3875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>19.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>29.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.7750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>177 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass  Sex    Age  Siblings/Spouses Aboard  Parents/Children Aboard  \\\n",
       "405       2    0   3.00                        1                      1.0   \n",
       "792       1    1  49.00                        0                      0.0   \n",
       "303       1    0   0.92                        1                      2.0   \n",
       "15        2    1  55.00                        0                      0.0   \n",
       "430       3    0  17.00                        0                      0.0   \n",
       "..      ...  ...    ...                      ...                      ...   \n",
       "60        1    1  38.00                        0                      0.0   \n",
       "222       3    0  22.00                        0                      0.0   \n",
       "569       1    0  36.00                        0                      0.0   \n",
       "424       2    1  19.00                        0                      0.0   \n",
       "106       3    0  29.00                        0                      0.0   \n",
       "\n",
       "         Fare  \n",
       "405   18.7500  \n",
       "792   25.9292  \n",
       "303  151.5500  \n",
       "15    16.0000  \n",
       "430    7.1250  \n",
       "..        ...  \n",
       "60    80.0000  \n",
       "222    7.8958  \n",
       "569   26.3875  \n",
       "424   26.0000  \n",
       "106    7.7750  \n",
       "\n",
       "[177 rows x 6 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Taking a look at the training features dataset (20% of original)\n",
    "test_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZGxPXEAhVbHg"
   },
   "source": [
    "## 1.8. Scale the columns using min-max scalers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "8C_1EttXUiar"
   },
   "outputs": [],
   "source": [
    "# min_max_scaler function \n",
    "# Performs min-max normalization of df\n",
    "def min_max_scaler(df):\n",
    "    \n",
    "    norm_df = df.copy()\n",
    "\n",
    "    for col in range(len(norm_df.columns)):\n",
    "        min_a = min(norm_df.iloc[:,col])  # min value of a specific column \n",
    "        max_a = max(norm_df.iloc[:,col])  # max value of a specific column\n",
    "\n",
    "        for row in range(len(norm_df)):\n",
    "            # min-max normalization of each data point in each column\n",
    "            norm_df.iloc[row,col] = (norm_df.iloc[row,col] - min_a)/(max_a - min_a)\n",
    "     \n",
    "    return norm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S2ZFsfbkY85Z"
   },
   "outputs": [],
   "source": [
    "# Call this function on the training and testing feature data\n",
    "sc_train_feat = min_max_scaler(train_features)\n",
    "sc_test_feat = min_max_scaler(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "hbMcM42yVmAu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pclass                     1.0\n",
      "Sex                        1.0\n",
      "Age                        1.0\n",
      "Siblings/Spouses Aboard    1.0\n",
      "Parents/Children Aboard    1.0\n",
      "Fare                       1.0\n",
      "dtype: float64\n",
      "Pclass                     0.0\n",
      "Sex                        0.0\n",
      "Age                        0.0\n",
      "Siblings/Spouses Aboard    0.0\n",
      "Parents/Children Aboard    0.0\n",
      "Fare                       0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Min and max values of scaled training data is 0 and 1, respectively.\n",
    "print(sc_train_feat.max())\n",
    "print(sc_train_feat.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "_SAdcnPfA0OE"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Siblings/Spouses Aboard</th>\n",
       "      <th>Parents/Children Aboard</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.572757</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.119406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.723549</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.221098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.484795</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.097594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.371701</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.321438</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.246042</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.271174</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.447097</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.220910</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.283740</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>710 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass  Sex       Age  Siblings/Spouses Aboard  Parents/Children Aboard  \\\n",
       "91      0.0    0  0.572757                    0.125                 0.000000   \n",
       "656     0.0    0  0.723549                    0.000                 0.333333   \n",
       "184     0.0    0  0.484795                    0.000                 0.000000   \n",
       "44      1.0    0  0.371701                    0.000                 0.000000   \n",
       "2       1.0    1  0.321438                    0.000                 0.000000   \n",
       "..      ...  ...       ...                      ...                      ...   \n",
       "438     1.0    0  0.246042                    0.000                 0.000000   \n",
       "585     1.0    0  0.271174                    0.000                 0.000000   \n",
       "580     0.0    0  0.447097                    0.000                 0.000000   \n",
       "36      1.0    0  0.220910                    0.000                 0.000000   \n",
       "730     0.5    0  0.283740                    0.000                 0.000000   \n",
       "\n",
       "         Fare  \n",
       "91   0.119406  \n",
       "656  0.221098  \n",
       "184  0.097594  \n",
       "44   0.015713  \n",
       "2    0.015469  \n",
       "..        ...  \n",
       "438  0.018543  \n",
       "585  0.015713  \n",
       "580  0.078319  \n",
       "36   0.014110  \n",
       "730  0.025374  \n",
       "\n",
       "[710 rows x 6 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at the scaled training feature data as an example\n",
    "# All values between 0 and 1\n",
    "sc_train_feat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Py_a1oekVg8i"
   },
   "source": [
    "## 1.9 Print the shape of the train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "jNztyBstVuZy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(710, 6) (710,)\n",
      "(177, 6) (177,)\n"
     ]
    }
   ],
   "source": [
    "# Training set:\n",
    "# Features dataframe containing 710 rows for 6 feature columns  \n",
    "# Series of 710 target labels\n",
    "print(sc_train_feat.shape, train_labels.shape)\n",
    "\n",
    "# Testing set:\n",
    "# Features dataframe containing 177 rows of data for 6 features\n",
    "# Series of 177 target labels\n",
    "print(sc_test_feat.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cnIPDFkDRgQK"
   },
   "source": [
    "# Part 2 - k-NN implementation\n",
    "\n",
    "NOTE: My observed results may differ to other test runs due to randomization of the data at the start."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_3lrx1Zi1yiA"
   },
   "source": [
    "## 2.1 Defining Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FOX05M1iCarT"
   },
   "source": [
    "All functions for K-NN implementation will be defined here before being called upon in later sections of Part 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "9csM9Gv2Q9Yr"
   },
   "outputs": [],
   "source": [
    "# euclid_calc function\n",
    "# Returns a dictionary containing the Euclidian distances of all training data \n",
    "# points from a specific row of testing query data.\n",
    "\n",
    "def euclid_calc(query_index, train_df, test_df):\n",
    "\n",
    "    euclids = {}\n",
    "    # the row of testing data we are aiming to predict\n",
    "    query_row = test_df.iloc[query_index,:]\n",
    "\n",
    "    # calculate the Euclidian distance of all training data points\n",
    "    for row in range(len(train_df)):\n",
    "        # sum the squared distances\n",
    "        sqrd_distance = 0\n",
    "        for col in range(len(train_df.columns)):\n",
    "            # Euclidian calculation\n",
    "            calc = (train_df.iloc[row,col] - query_row[col])**2\n",
    "            sqrd_distance += calc\n",
    "\n",
    "        # get the square root of the sum of squared distances\n",
    "        euclids[row] = sqrd_distance**0.5\n",
    "\n",
    "    return euclids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "X8Z1RQywA0V0"
   },
   "outputs": [],
   "source": [
    "# index_dict function\n",
    "# Returns a dictionary containing an enumerated version of the original randomized indexes\n",
    "# e.g. if the first two rows of a df were indexes 122 and 450 after randomization, \n",
    "# the dictionary will be {0:122, 1:450....}\n",
    "# Required for keeping track of what values the randnomized index numbers actually correspond to.\n",
    "\n",
    "def index_dict(df):\n",
    "    \n",
    "    row_inds = {}\n",
    "    for i in range(len(df.index)):\n",
    "        row_inds[i] = df.index[i]\n",
    "    \n",
    "    return row_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "UISuzYQcBLU8"
   },
   "outputs": [],
   "source": [
    "# knn_fit function\n",
    "# Computes the predicted results from a dictionary of Euclidian distances.\n",
    "# Extracts k points with the smallest distance to the query point.\n",
    "# Selects the most common class among the k points as the prediction value.\n",
    "# Returns a dictionary containing the actual and predicted target label of each row.\n",
    "# Default k set to 5, but can be changed.\n",
    "\n",
    "def knn_fit(train_feat, test_feat, train_labels, test_labels, euclid_dists, k=5):\n",
    "    \n",
    "    # To keep track of train and test features indexing\n",
    "    train_ind = index_dict(train_feat)\n",
    "    test_ind = index_dict(test_feat)\n",
    "\n",
    "    results = {}    \n",
    "    for d in range(len(euclid_dists)):\n",
    "\n",
    "        # In the results dictionary, assign the row number of the test data being predicted \n",
    "        # to another dictionary containg the actual test label for this specific row.\n",
    "        results['Test row ' + str(test_ind[d])] = {'Actual':test_labels[test_ind[d]]}\n",
    "\n",
    "        # k nearest neighbours found by sorting the dictionary \n",
    "        k_nearest = sorted(euclid_dists[d].values())[:k]\n",
    "        \n",
    "        # Store classes of the k nearest neighbours\n",
    "        classes = []\n",
    "        for key, value in euclid_dists[d].items():\n",
    "            \n",
    "            if value in k_nearest:\n",
    "                # correct index of training row corresponding to k nearest value\n",
    "                index = train_ind[key]\n",
    "                # append 1 or 0 label to classes list\n",
    "                classes.append(train_labels[index])\n",
    "   \n",
    "        # count classes in the list and assign prediction as most common label\n",
    "        if classes.count(1) > classes.count(0):\n",
    "            results['Test row ' + str(test_ind[d])]['Prediction'] = 1 \n",
    "        else:\n",
    "            results['Test row ' + str(test_ind[d])]['Prediction'] = 0\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "1TRpwe7eBbgC"
   },
   "outputs": [],
   "source": [
    "# evaluate_knn function\n",
    "# Computes the accuracy of a particular K-NN model.\n",
    "# Takes the K-NN results dictionary as input.\n",
    "\n",
    "def evaluate_knn(result_dict):\n",
    "    \n",
    "    score = 0\n",
    "    for d in result_dict.values():\n",
    "        # if prediction correct\n",
    "        if d['Actual'] == d['Prediction']:\n",
    "            score +=1\n",
    "    \n",
    "    # correct predictions over total predictions\n",
    "    accuracy = score/len(result_dict)\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "\n",
    "# confusion_matrix function\n",
    "# Generates confusion matrix from the K-NN results dictionary as input.  \n",
    "# Confusion matrix/Table visualization code inspired from \n",
    "# https://pandas.pydata.org/pandas-docs/stable/user_guide/style.html \n",
    "# https://www.statology.org/confusion-matrix-python/\n",
    "\n",
    "def confusion_matrix(result_dict):\n",
    "    \n",
    "    actual = []\n",
    "    predicted = []\n",
    "    \n",
    "    for d in result_dict.values():\n",
    "        actual.append(d['Actual'])        # Actual test label\n",
    "        predicted.append(d['Prediction']) # Predicted test label\n",
    "      \n",
    "    # Make each list into a series\n",
    "    actual = pd.Series(actual, name='Actual')\n",
    "    predicted = pd.Series(predicted, name='Predicted')\n",
    "\n",
    "    # Use crosstab function to get contingency table/confusion matrix\n",
    "    conf_mat = pd.crosstab(actual, predicted)\n",
    "    \n",
    "    # Formatting the confusion matrix\n",
    "    conf_mat = conf_mat.style.background_gradient(cmap ='Blues')\\\n",
    "                .set_properties(**{'font-size': '35px'})\n",
    "    \n",
    "    return conf_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ujE7xxM-D4gR"
   },
   "source": [
    "## 2.2 Euclidian Distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u41USXj2Srpw"
   },
   "source": [
    "For each of the rows in the testing dataset, the Euclidian distances are calculated between all training dataset rows and the testing data row being queried. Each dictionary of Euclidian distances for each query row is then stored in a new dictionary, reuslting in a dictioanry of dictionaries. \n",
    "\n",
    "This ***euclid_calc*** function was made separate to the ***knn_fit*** function as it takes some time (~30s) to compute. Once calculated, this euclidian distances dictionary can be accessed and used as input for other functions, alleviating the need for repeating the computation if a new k value was to be tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "P0YlMztC0uwk"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\conor\\AppData\\Local\\Temp\\ipykernel_20752\\651777586.py:17: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  calc = (train_df.iloc[row,col] - query_row[col])**2\n"
     ]
    }
   ],
   "source": [
    "euclid_dists = {}\n",
    "\n",
    "# Iterating through each row of the scaled testing data\n",
    "for i in range(len(sc_test_feat)):\n",
    "    euclid_dists[i] = euclid_calc(i, sc_train_feat, sc_test_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g7oBQTLEbkus"
   },
   "source": [
    "\n",
    "The first key of this new dictionary is the reference index* (0-177) of the testing row in question, with the value of each of these keys being the dictionary of Euclidian distances calculated for all 710 training rows. So the euclid_dists dictionary contains 177 keys, each of which contain a dictionary of 710 keys (training row index) with 710 values (Euclidian distances). An example subset of this dictionary can be seen below. This is the first dictionary of Euclidian distances i.e. the Euclidian distances between all training row data and the first row of testing data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "qgp5Bj3vbtLx"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.7676703903442695,\n",
       " 1: 0.8920409925196864,\n",
       " 2: 0.7172200489792645,\n",
       " 3: 0.6492187409007891,\n",
       " 4: 1.1789267578257463,\n",
       " 5: 1.1512214753868275,\n",
       " 6: 0.5979259132223799,\n",
       " 7: 1.1514087059340439,\n",
       " 8: 1.2116202320538965,\n",
       " 9: 0.7478698953985591,\n",
       " 10: 0.6186811250409844,\n",
       " 11: 0.718454151317223,\n",
       " 12: 0.7314202660496374,\n",
       " 13: 0.5932183336469747,\n",
       " 14: 0.5978139766026666,\n",
       " 15: 0.4667851335696587,\n",
       " 16: 1.347396778235987,\n",
       " 17: 0.8281568338640459,\n",
       " 18: 0.5607476353938214,\n",
       " 19: 1.1583934469018868,\n",
       " 20: 0.8824513059511043,\n",
       " 21: 0.6697341648931932,\n",
       " 22: 1.1692416719861858,\n",
       " 23: 0.5806235341918573,\n",
       " 24: 0.9155936677593701,\n",
       " 25: 1.2009730497217288,\n",
       " 26: 1.0198825195403842,\n",
       " 27: 1.0745834889897843,\n",
       " 28: 0.7938569912373719,\n",
       " 29: 0.7309642390411866,\n",
       " 30: 1.1604721949240526,\n",
       " 31: 0.3450651010454138,\n",
       " 32: 0.6174950944376515,\n",
       " 33: 1.224933211243321,\n",
       " 34: 1.08220827539334,\n",
       " 35: 1.0501887092011504,\n",
       " 36: 0.8929298079873467,\n",
       " 37: 1.1256750613215707,\n",
       " 38: 0.7987640505425359,\n",
       " 39: 0.03818283863166163,\n",
       " 40: 0.6697266646297458,\n",
       " 41: 0.47758701345089755,\n",
       " 42: 0.6303815321635309,\n",
       " 43: 0.20725301980157174,\n",
       " 44: 0.5377441940491929,\n",
       " 45: 0.6243968279496704,\n",
       " 46: 0.5935344663937697,\n",
       " 47: 1.158305808661738,\n",
       " 48: 0.6240929717886581,\n",
       " 49: 0.6027881288003706,\n",
       " 50: 1.1034978004447722,\n",
       " 51: 0.6186707518822973,\n",
       " 52: 0.41633201650870905,\n",
       " 53: 1.2731675092735082,\n",
       " 54: 0.638487065337719,\n",
       " 55: 0.6303203408771393,\n",
       " 56: 0.32914017720188504,\n",
       " 57: 0.5887790142818662,\n",
       " 58: 0.6015716000888971,\n",
       " 59: 0.18580028631085568,\n",
       " 60: 0.7823090292569396,\n",
       " 61: 1.0130716698454434,\n",
       " 62: 1.038399220750375,\n",
       " 63: 1.269439995034412,\n",
       " 64: 1.041685283336676,\n",
       " 65: 0.63032693158403,\n",
       " 66: 1.2590128181970313,\n",
       " 67: 0.6556866970395613,\n",
       " 68: 0.7155581568442367,\n",
       " 69: 0.5887972274849989,\n",
       " 70: 0.7838920561768027,\n",
       " 71: 1.269618443404413,\n",
       " 72: 1.1675403550347878,\n",
       " 73: 1.2008873321556526,\n",
       " 74: 1.1706193165131695,\n",
       " 75: 0.44524677129950485,\n",
       " 76: 0.6027528030013375,\n",
       " 77: 0.9154667484119685,\n",
       " 78: 0.597872084376371,\n",
       " 79: 1.0179341555073247,\n",
       " 80: 0.712576981650919,\n",
       " 81: 1.192240104130776,\n",
       " 82: 0.4897896164798131,\n",
       " 83: 0.630391655259873,\n",
       " 84: 0.7149740833238285,\n",
       " 85: 1.067323271479546,\n",
       " 86: 0.6491338580352075,\n",
       " 87: 0.8613301480196092,\n",
       " 88: 0.7693084770259232,\n",
       " 89: 0.5932256599196131,\n",
       " 90: 0.8470096945170007,\n",
       " 91: 0.9253112763831501,\n",
       " 92: 0.6363408592313586,\n",
       " 93: 1.229578325000705,\n",
       " 94: 0.9661824490720252,\n",
       " 95: 1.231647341648152,\n",
       " 96: 0.6064372937382351,\n",
       " 97: 0.612873837996668,\n",
       " 98: 0.5887864745683925,\n",
       " 99: 0.6237072661116692,\n",
       " 100: 1.1479497090578075,\n",
       " 101: 0.6478379500587732,\n",
       " 102: 0.6627243241941808,\n",
       " 103: 0.5846261647455023,\n",
       " 104: 0.6097611903667994,\n",
       " 105: 0.7740507317289551,\n",
       " 106: 1.2213760153516766,\n",
       " 107: 1.2433156106598862,\n",
       " 108: 1.167627464982667,\n",
       " 109: 1.1583556243680242,\n",
       " 110: 1.0094383237190943,\n",
       " 111: 0.6027409928324826,\n",
       " 112: 0.6240367547961398,\n",
       " 113: 0.8095760239546885,\n",
       " 114: 1.0340360275640406,\n",
       " 115: 0.3834776896893636,\n",
       " 116: 0.413893819968831,\n",
       " 117: 0.5846273627592149,\n",
       " 118: 0.7070000444525647,\n",
       " 119: 1.146203820302154,\n",
       " 120: 0.7076727834832447,\n",
       " 121: 0.5888146856697967,\n",
       " 122: 0.7155581568442367,\n",
       " 123: 1.2617516433216143,\n",
       " 124: 0.7270290773165292,\n",
       " 125: 0.04277631328848464,\n",
       " 126: 0.6626976483895122,\n",
       " 127: 1.0990850442582394,\n",
       " 128: 0.7647771433726054,\n",
       " 129: 0.7004893944511918,\n",
       " 130: 1.1676081721865237,\n",
       " 131: 0.6243861382059472,\n",
       " 132: 0.4559107277017861,\n",
       " 133: 0.39335693054712784,\n",
       " 134: 1.2866061101287705,\n",
       " 135: 0.642767862769504,\n",
       " 136: 1.0425495654145833,\n",
       " 137: 0.669929286498584,\n",
       " 138: 1.2033953956349497,\n",
       " 139: 1.1627195206011898,\n",
       " 140: 0.6302843931406827,\n",
       " 141: 1.0294279273947267,\n",
       " 142: 0.5769724852497438,\n",
       " 143: 1.1999834268055758,\n",
       " 144: 0.856298987925939,\n",
       " 145: 0.6839217505942348,\n",
       " 146: 0.649272253972181,\n",
       " 147: 0.7893552764502896,\n",
       " 148: 0.7914240839957241,\n",
       " 149: 0.5888090177818711,\n",
       " 150: 1.1158809008392478,\n",
       " 151: 1.0522609842297306,\n",
       " 152: 0.13750306594082295,\n",
       " 153: 0.3639101737630909,\n",
       " 154: 1.1690363530318373,\n",
       " 155: 0.38338081258345347,\n",
       " 156: 0.5355567449239889,\n",
       " 157: 1.196865369850807,\n",
       " 158: 1.2430719746353587,\n",
       " 159: 1.172707616352604,\n",
       " 160: 0.9971381601497719,\n",
       " 161: 1.0609567422999515,\n",
       " 162: 0.6131493241438416,\n",
       " 163: 1.1562033488745602,\n",
       " 164: 1.090359141263953,\n",
       " 165: 0.5013257994550426,\n",
       " 166: 1.1676265258924712,\n",
       " 167: 1.1661519146418104,\n",
       " 168: 1.1853407916465155,\n",
       " 169: 0.45956228600469423,\n",
       " 170: 1.3140412526292522,\n",
       " 171: 1.547847655540579,\n",
       " 172: 1.184560209168249,\n",
       " 173: 0.6243472927343352,\n",
       " 174: 0.33791602502588414,\n",
       " 175: 1.1594084857745897,\n",
       " 176: 0.6075248668319099,\n",
       " 177: 1.0289481212557137,\n",
       " 178: 1.1186184691997418,\n",
       " 179: 1.0161910847867168,\n",
       " 180: 1.1958808962313423,\n",
       " 181: 0.6769791207436875,\n",
       " 182: 0.7744300184802089,\n",
       " 183: 0.7093497424324923,\n",
       " 184: 0.6078403923212988,\n",
       " 185: 1.1258377805447388,\n",
       " 186: 0.5798940701071509,\n",
       " 187: 1.172977683415965,\n",
       " 188: 1.191301338617886,\n",
       " 189: 0.5806235341918573,\n",
       " 190: 0.7070433034505851,\n",
       " 191: 0.8030776263993732,\n",
       " 192: 0.6840354946305234,\n",
       " 193: 0.6492284929022687,\n",
       " 194: 1.3683939350889807,\n",
       " 195: 1.0185875673495628,\n",
       " 196: 1.185349129782353,\n",
       " 197: 1.167607275906495,\n",
       " 198: 1.1721079758088941,\n",
       " 199: 0.6193900505846168,\n",
       " 200: 0.6842535836776857,\n",
       " 201: 0.629268711809938,\n",
       " 202: 0.6119196348525856,\n",
       " 203: 0.8274625987419088,\n",
       " 204: 1.2042982754748284,\n",
       " 205: 0.5751229498752422,\n",
       " 206: 0.567126230374833,\n",
       " 207: 0.8398060054856521,\n",
       " 208: 0.6696349266336142,\n",
       " 209: 1.1545230406070024,\n",
       " 210: 1.1676081721865237,\n",
       " 211: 0.6240392741164638,\n",
       " 212: 1.1940763895108468,\n",
       " 213: 0.31236630839869495,\n",
       " 214: 0.8665203504325566,\n",
       " 215: 0.8186704694715884,\n",
       " 216: 0.6282667157398707,\n",
       " 217: 1.178929242637989,\n",
       " 218: 1.3626326979624934,\n",
       " 219: 0.6664721192134755,\n",
       " 220: 0.7220841180992386,\n",
       " 221: 0.6078846008697475,\n",
       " 222: 0.6369979151396916,\n",
       " 223: 1.1959085802301581,\n",
       " 224: 1.0457609749420451,\n",
       " 225: 1.1791916332371069,\n",
       " 226: 0.3106326340007782,\n",
       " 227: 1.1872936245065122,\n",
       " 228: 0.7393888732997078,\n",
       " 229: 1.1178494300611295,\n",
       " 230: 1.1602594357422986,\n",
       " 231: 1.2049068965902765,\n",
       " 232: 0.5795437336239043,\n",
       " 233: 1.1944045147459312,\n",
       " 234: 0.6367499856522776,\n",
       " 235: 0.5806866606629588,\n",
       " 236: 0.7308618297913038,\n",
       " 237: 0.6364401044714911,\n",
       " 238: 0.6364469332095565,\n",
       " 239: 0.6877181407487081,\n",
       " 240: 1.1429916610470643,\n",
       " 241: 1.1328402352017928,\n",
       " 242: 0.43831828313535026,\n",
       " 243: 0.7827664077862544,\n",
       " 244: 0.34517185685841445,\n",
       " 245: 1.3217881957681596,\n",
       " 246: 0.7831480533902544,\n",
       " 247: 0.34517185685841445,\n",
       " 248: 1.193944819481554,\n",
       " 249: 1.3085505965176827,\n",
       " 250: 0.6273378764046313,\n",
       " 251: 1.0425323318829978,\n",
       " 252: 1.1271356627748639,\n",
       " 253: 0.595557852868621,\n",
       " 254: 1.2108435714150705,\n",
       " 255: 1.1618727423075645,\n",
       " 256: 0.4036429762949529,\n",
       " 257: 1.0710945805418057,\n",
       " 258: 0.6027866156176012,\n",
       " 259: 0.5768945431794957,\n",
       " 260: 1.213249717152391,\n",
       " 261: 1.2757119992123414,\n",
       " 262: 0.8662172347532474,\n",
       " 263: 0.6833794959968108,\n",
       " 264: 0.6627261437458078,\n",
       " 265: 0.6441243496442833,\n",
       " 266: 1.1769615245336404,\n",
       " 267: 1.1279842952127948,\n",
       " 268: 1.1785965412635904,\n",
       " 269: 0.5931284383489175,\n",
       " 270: 1.0468072498328032,\n",
       " 271: 0.662728744440808,\n",
       " 272: 0.31055271959088776,\n",
       " 273: 0.5766227137347667,\n",
       " 274: 1.1894345207724766,\n",
       " 275: 0.3639101737630909,\n",
       " 276: 1.1604807221161797,\n",
       " 277: 0.5978631189447344,\n",
       " 278: 0.6263327914260096,\n",
       " 279: 1.175909667254975,\n",
       " 280: 0.5180174859059957,\n",
       " 281: 0.6303596354066566,\n",
       " 282: 1.2564181983184926,\n",
       " 283: 1.1650986481993484,\n",
       " 284: 0.6027519324283259,\n",
       " 285: 0.5505534706472694,\n",
       " 286: 0.8028761678300947,\n",
       " 287: 0.6364373963523686,\n",
       " 288: 0.5930916936508626,\n",
       " 289: 0.5465762130009901,\n",
       " 290: 0.5888075359657765,\n",
       " 291: 0.9256175611755342,\n",
       " 292: 0.5932633210075927,\n",
       " 293: 1.2339485950049653,\n",
       " 294: 0.506849182103586,\n",
       " 295: 1.2201943798407606,\n",
       " 296: 1.1211208366672507,\n",
       " 297: 1.0811607446613696,\n",
       " 298: 0.7393475068335753,\n",
       " 299: 0.6364469332095565,\n",
       " 300: 1.0842062754079316,\n",
       " 301: 0.8177026974011532,\n",
       " 302: 1.2201894589593383,\n",
       " 303: 1.1581575497899264,\n",
       " 304: 1.2496697450021503,\n",
       " 305: 1.1461378261891504,\n",
       " 306: 1.1653823451082401,\n",
       " 307: 1.1514217031921383,\n",
       " 308: 1.1081919307669352,\n",
       " 309: 1.2130143357315908,\n",
       " 310: 0.5932133954534718,\n",
       " 311: 0.905267120227142,\n",
       " 312: 1.0093271498381282,\n",
       " 313: 0.6482609896312147,\n",
       " 314: 0.7392317020516712,\n",
       " 315: 1.1676081721865237,\n",
       " 316: 1.211690463087661,\n",
       " 317: 0.6400483192375526,\n",
       " 318: 1.1553169688536225,\n",
       " 319: 1.2106081791557388,\n",
       " 320: 0.39437139532287335,\n",
       " 321: 0.8491753537363261,\n",
       " 322: 1.15282607692855,\n",
       " 323: 0.6696814716267031,\n",
       " 324: 0.5895529752470329,\n",
       " 325: 1.1399277112700898,\n",
       " 326: 0.5932047553852275,\n",
       " 327: 1.24935785172014,\n",
       " 328: 0.5932183336469747,\n",
       " 329: 1.1881272629608701,\n",
       " 330: 0.5754648406139444,\n",
       " 331: 1.1651030171389127,\n",
       " 332: 0.5359712412098052,\n",
       " 333: 1.1870749797777467,\n",
       " 334: 1.246584731337885,\n",
       " 335: 0.6923169618114804,\n",
       " 336: 1.0186376327538538,\n",
       " 337: 0.6078375567809295,\n",
       " 338: 1.1258377805447388,\n",
       " 339: 0.35463016215529336,\n",
       " 340: 0.6427481249792827,\n",
       " 341: 0.5178383518707284,\n",
       " 342: 0.7278122142528262,\n",
       " 343: 1.261491470467876,\n",
       " 344: 1.436129549629765,\n",
       " 345: 0.5978545460733204,\n",
       " 346: 0.6916735068536829,\n",
       " 347: 0.4137327051730709,\n",
       " 348: 0.6131389983019385,\n",
       " 349: 0.5932766818727401,\n",
       " 350: 0.6842584537574681,\n",
       " 351: 0.6842471389028878,\n",
       " 352: 1.0745908411765697,\n",
       " 353: 1.1149920779122195,\n",
       " 354: 0.5106233938511876,\n",
       " 355: 1.236936422556655,\n",
       " 356: 0.6992860081234857,\n",
       " 357: 1.0377794548223511,\n",
       " 358: 0.6263512305377648,\n",
       " 359: 0.6131560994189938,\n",
       " 360: 0.6627165903648738,\n",
       " 361: 0.6026479005173772,\n",
       " 362: 0.4559107277017861,\n",
       " 363: 1.1443113072327709,\n",
       " 364: 0.9455630035178898,\n",
       " 365: 1.2253021633313426,\n",
       " 366: 1.1651059074318282,\n",
       " 367: 0.6128461438352044,\n",
       " 368: 0.6909592979802508,\n",
       " 369: 1.1675213548051304,\n",
       " 370: 1.1279436586185025,\n",
       " 371: 0.7394027758439993,\n",
       " 372: 0.5811281065567461,\n",
       " 373: 0.8004620290783562,\n",
       " 374: 1.1820750062487226,\n",
       " 375: 1.1535504473689533,\n",
       " 376: 0.5532720781491516,\n",
       " 377: 0.7912847626369216,\n",
       " 378: 0.38338081258345347,\n",
       " 379: 0.6361273499806095,\n",
       " 380: 1.1655111008019137,\n",
       " 381: 0.6186873670934351,\n",
       " 382: 1.2905498791761936,\n",
       " 383: 1.1583649272104246,\n",
       " 384: 0.6899995776700999,\n",
       " 385: 0.6768787290501533,\n",
       " 386: 1.2706245534134368,\n",
       " 387: 0.5896472197481767,\n",
       " 388: 0.618729485492281,\n",
       " 389: 0.5444015257997423,\n",
       " 390: 0.03621566954165542,\n",
       " 391: 0.4363768615725419,\n",
       " 392: 0.6427513776072951,\n",
       " 393: 0.3106326340007782,\n",
       " 394: 1.086516758226975,\n",
       " 395: 0.6078375567809295,\n",
       " 396: 1.1331575280070927,\n",
       " 397: 1.1702410365851363,\n",
       " 398: 1.147883815319409,\n",
       " 399: 0.5887864745683925,\n",
       " 400: 0.5887972274849989,\n",
       " 401: 0.624422968309422,\n",
       " 402: 0.5975120324745818,\n",
       " 403: 0.6236861015589771,\n",
       " 404: 1.1650986481993484,\n",
       " 405: 1.2751847505168061,\n",
       " 406: 1.279633749368343,\n",
       " 407: 0.38348746411171375,\n",
       " 408: 0.6027866156176012,\n",
       " 409: 1.1413914805435488,\n",
       " 410: 1.000674567262678,\n",
       " 411: 0.6364355016419388,\n",
       " 412: 0.5886541771165504,\n",
       " 413: 0.6077526598383939,\n",
       " 414: 0.37373944166400386,\n",
       " 415: 0.6767277283048887,\n",
       " 416: 0.578881329528382,\n",
       " 417: 0.8187952938120044,\n",
       " 418: 0.8188104389564776,\n",
       " 419: 0.655889833309418,\n",
       " 420: 0.34517185685841445,\n",
       " 421: 0.6505106731859975,\n",
       " 422: 0.6078375567809295,\n",
       " 423: 0.6187152000408926,\n",
       " 424: 0.5239214693046896,\n",
       " 425: 0.5601591479813681,\n",
       " 426: 0.42219049842864353,\n",
       " 427: 1.1853546925208405,\n",
       " 428: 0.5845877234688288,\n",
       " 429: 0.7649408267164405,\n",
       " 430: 1.0365063934138075,\n",
       " 431: 0.7649709286465176,\n",
       " 432: 0.6427281314209151,\n",
       " 433: 0.8010118283869143,\n",
       " 434: 0.6427497494430525,\n",
       " 435: 0.8757260543930038,\n",
       " 436: 0.597876459494525,\n",
       " 437: 0.5630564646858903,\n",
       " 438: 1.1545195694394645,\n",
       " 439: 1.2248743119788352,\n",
       " 440: 0.5978680187330494,\n",
       " 441: 0.6027478851040061,\n",
       " 442: 1.0217090658301893,\n",
       " 443: 0.7477761563002214,\n",
       " 444: 0.5107683884734185,\n",
       " 445: 1.1650986481993484,\n",
       " 446: 0.618729485492281,\n",
       " 447: 0.5444015257997423,\n",
       " 448: 1.263439206776344,\n",
       " 449: 0.6481798990716986,\n",
       " 450: 1.1891686937144998,\n",
       " 451: 1.1702544809767115,\n",
       " 452: 0.5888075359657765,\n",
       " 453: 1.177893496248534,\n",
       " 454: 0.6489683224926062,\n",
       " 455: 1.074213680327813,\n",
       " 456: 0.4137327051730709,\n",
       " 457: 1.1554710318502681,\n",
       " 458: 1.0745834889897843,\n",
       " 459: 0.6697266646297458,\n",
       " 460: 0.6627843431867991,\n",
       " 461: 0.5978697565055089,\n",
       " 462: 0.6598657128227775,\n",
       " 463: 0.30241152180868297,\n",
       " 464: 0.6059195866975302,\n",
       " 465: 0.66211339181643,\n",
       " 466: 1.288855791702985,\n",
       " 467: 0.6132085866008282,\n",
       " 468: 0.7562875932038797,\n",
       " 469: 0.5299824187382552,\n",
       " 470: 0.3453649571766794,\n",
       " 471: 0.6492284929022687,\n",
       " 472: 1.11861377865036,\n",
       " 473: 0.5769921641614466,\n",
       " 474: 1.2327759033658994,\n",
       " 475: 1.1959109025155963,\n",
       " 476: 1.2440389107256196,\n",
       " 477: 0.6130491198505806,\n",
       " 478: 1.071034168612614,\n",
       " 479: 0.6243962780503111,\n",
       " 480: 0.6303203408771393,\n",
       " 481: 1.0608701387380302,\n",
       " 482: 0.6492725379509853,\n",
       " 483: 0.5037169436396091,\n",
       " 484: 1.1611381048423812,\n",
       " 485: 0.6132093842711853,\n",
       " 486: 0.44741166586514414,\n",
       " 487: 0.7648449314959708,\n",
       " 488: 1.222698654469201,\n",
       " 489: 0.7825348585227914,\n",
       " 490: 1.3682855309563022,\n",
       " 491: 1.1546576793026286,\n",
       " 492: 1.2125592838350676,\n",
       " 493: 1.155912699960786,\n",
       " 494: 0.3441133212590227,\n",
       " 495: 0.6364439237139806,\n",
       " 496: 0.6916978614145896,\n",
       " 497: 0.611759069525726,\n",
       " 498: 1.1358199422001165,\n",
       " 499: 1.0636357692592258,\n",
       " 500: 0.7028388698468143,\n",
       " 501: 1.1518181205936866,\n",
       " 502: 0.7653242300119032,\n",
       " 503: 0.5972135876282499,\n",
       " 504: 0.9854519381995488,\n",
       " 505: 0.6558993302888108,\n",
       " 506: 1.1507507614946584,\n",
       " 507: 0.6027957503672511,\n",
       " 508: 0.6026690859495346,\n",
       " 509: 0.5619817103435724,\n",
       " 510: 0.4137327051730709,\n",
       " 511: 0.4347601635573677,\n",
       " 512: 1.0536026291083695,\n",
       " 513: 0.7478480209475913,\n",
       " 514: 1.2067622287211972,\n",
       " 515: 0.5807251349285614,\n",
       " 516: 0.6027671643457772,\n",
       " 517: 1.1604669530150322,\n",
       " 518: 0.6768787290501533,\n",
       " 519: 0.5932047553852275,\n",
       " 520: 0.6842053453135435,\n",
       " 521: 1.2537309657050202,\n",
       " 522: 1.1923172805607924,\n",
       " 523: 0.6364274483524707,\n",
       " 524: 0.7230451690183414,\n",
       " 525: 1.1621270712636182,\n",
       " 526: 1.1692813012279055,\n",
       " 527: 0.6709116201544896,\n",
       " 528: 0.5846228884893515,\n",
       " 529: 0.6922228969346321,\n",
       " 530: 1.1380671154209643,\n",
       " 531: 1.2590158151360438,\n",
       " 532: 0.34187703286507237,\n",
       " 533: 0.5846643797692251,\n",
       " 534: 0.5901575227693032,\n",
       " 535: 0.6027304886774367,\n",
       " 536: 0.5978717912598459,\n",
       " 537: 0.6467859052860823,\n",
       " 538: 1.1993898424277407,\n",
       " 539: 0.7256381904809932,\n",
       " 540: 0.7394085208949611,\n",
       " 541: 0.7848864777446755,\n",
       " 542: 1.2092747154279455,\n",
       " 543: 0.4668483830622799,\n",
       " 544: 0.649118929218931,\n",
       " 545: 1.3067486256055088,\n",
       " 546: 1.2403664224011857,\n",
       " 547: 0.8660371930209527,\n",
       " 548: 0.6027884346782455,\n",
       " 549: 0.35566927710603624,\n",
       " 550: 1.165102261471619,\n",
       " 551: 1.042590675561637,\n",
       " 552: 1.1627868741152303,\n",
       " 553: 0.5846049527070587,\n",
       " 554: 0.5044139257517718,\n",
       " 555: 1.1743537084300286,\n",
       " 556: 0.8955230950652925,\n",
       " 557: 0.7692149654039132,\n",
       " 558: 0.8313167177085394,\n",
       " 559: 0.6027510628416631,\n",
       " 560: 0.6131389983019385,\n",
       " 561: 1.173010429469415,\n",
       " 562: 0.18783234435518664,\n",
       " 563: 0.6362668476610903,\n",
       " 564: 0.6799833868085549,\n",
       " 565: 0.7824301780686108,\n",
       " 566: 0.37003155385194375,\n",
       " 567: 1.1081919307669352,\n",
       " 568: 1.1450266758109686,\n",
       " 569: 0.639236504832859,\n",
       " 570: 0.7313234770414094,\n",
       " 571: 0.30260391122042685,\n",
       " 572: 0.32914017720188504,\n",
       " 573: 0.649272253972181,\n",
       " 574: 1.0990243817284364,\n",
       " 575: 0.58462437470402,\n",
       " 576: 1.11890163126266,\n",
       " 577: 0.6991325159364528,\n",
       " 578: 0.768684207089094,\n",
       " 579: 1.082222176448961,\n",
       " 580: 0.6427864238152284,\n",
       " 581: 0.6841960918452255,\n",
       " 582: 1.3624996711139679,\n",
       " 583: 0.5978894342038031,\n",
       " 584: 0.584662819679858,\n",
       " 585: 1.125629507751538,\n",
       " 586: 1.1385837787765498,\n",
       " 587: 0.5749904076557053,\n",
       " 588: 0.7562943701812851,\n",
       " 589: 1.0396194406897363,\n",
       " 590: 0.6358478347147379,\n",
       " 591: 1.0578805755954797,\n",
       " 592: 1.232376814122432,\n",
       " 593: 0.6364373963523686,\n",
       " 594: 0.6244043228166988,\n",
       " 595: 0.6027304886774367,\n",
       " 596: 0.6627243241941808,\n",
       " 597: 0.393526387537128,\n",
       " 598: 1.1528075642712061,\n",
       " 599: 1.1527965154834852,\n",
       " 600: 1.1537160058688283,\n",
       " 601: 1.1854266992243205,\n",
       " 602: 0.7311578413861073,\n",
       " 603: 1.176555756276362,\n",
       " 604: 0.5768769720192797,\n",
       " 605: 0.5887972274849989,\n",
       " 606: 0.5769271249373394,\n",
       " 607: 0.6365339119037683,\n",
       " 608: 0.6078375567809295,\n",
       " 609: 0.6210677504958688,\n",
       " 610: 0.6396109947936093,\n",
       " 611: 0.636924327884193,\n",
       " 612: 0.6806221049006991,\n",
       " 613: 0.6915054905364606,\n",
       " 614: 0.7786067521266786,\n",
       " 615: 0.6305277516310852,\n",
       " 616: 0.6499139724030852,\n",
       " 617: 1.0772865591608918,\n",
       " 618: 1.3585124021935648,\n",
       " 619: 0.6664721192134755,\n",
       " 620: 0.7149339330121062,\n",
       " 621: 0.6768787290501533,\n",
       " 622: 1.2914024388632348,\n",
       " 623: 0.7229602028556131,\n",
       " 624: 0.8749215582132052,\n",
       " 625: 0.9558005156023919,\n",
       " 626: 1.154522433957296,\n",
       " 627: 0.5317215375070931,\n",
       " 628: 0.6427419342940119,\n",
       " 629: 1.1725415497226535,\n",
       " 630: 0.8565764360185195,\n",
       " 631: 0.6187169722706575,\n",
       " 632: 1.1702426540591406,\n",
       " 633: 0.5846646951288661,\n",
       " 634: 0.6664721192134755,\n",
       " 635: 1.1036045836380783,\n",
       " 636: 0.6364771137718178,\n",
       " 637: 0.5932154282138933,\n",
       " 638: 0.7070946965840232,\n",
       " 639: 0.905286814373624,\n",
       " 640: 0.7189241400721597,\n",
       " 641: 0.6105134252731099,\n",
       " 642: 1.168883449493044,\n",
       " 643: 1.3469105938212194,\n",
       " 644: 0.7298442336804463,\n",
       " 645: 1.1518148006085598,\n",
       " 646: 1.0924776944564238,\n",
       " 647: 0.5712038749973319,\n",
       " 648: 1.043582861733011,\n",
       " 649: 0.3413040452891474,\n",
       " 650: 0.635048684922458,\n",
       " 651: 1.1644508809876837,\n",
       " 652: 1.1633129570677172,\n",
       " 653: 1.1921404292496536,\n",
       " 654: 1.0091917705799345,\n",
       " 655: 0.04483826686906014,\n",
       " 656: 0.9389108361824041,\n",
       " 657: 0.3933302949539239,\n",
       " 658: 0.6840467063822648,\n",
       " 659: 0.6719351378256438,\n",
       " 660: 1.1560063930114912,\n",
       " 661: 0.6243962780503111,\n",
       " 662: 1.1515501453454928,\n",
       " 663: 1.1876263863115186,\n",
       " 664: 1.2035555428114448,\n",
       " 665: 0.7229997561923461,\n",
       " 666: 0.7228618147247853,\n",
       " 667: 0.5999208297184507,\n",
       " 668: 0.722951445433014,\n",
       " 669: 0.6059195866975302,\n",
       " 670: 0.5978288782573131,\n",
       " 671: 0.9456192339043948,\n",
       " 672: 0.7146993688960628,\n",
       " 673: 0.6294058690706089,\n",
       " 674: 0.597873537655732,\n",
       " 675: 0.6491204691357398,\n",
       " 676: 1.1582871423916552,\n",
       " 677: 1.2611370742885346,\n",
       " 678: 0.534243682535291,\n",
       " 679: 1.358718249432798,\n",
       " 680: 0.6027409928324826,\n",
       " 681: 0.6055436330371788,\n",
       " 682: 0.6598815900144733,\n",
       " 683: 0.7647771433726054,\n",
       " 684: 0.6303203408771393,\n",
       " 685: 1.3675751752561787,\n",
       " 686: 0.43831828313535026,\n",
       " 687: 1.3057728809655575,\n",
       " 688: 0.28761149039433537,\n",
       " 689: 0.7393888732997078,\n",
       " 690: 1.297377337508304,\n",
       " 691: 0.5979111307267292,\n",
       " 692: 1.2224362820839878,\n",
       " 693: 1.1721022226218607,\n",
       " 694: 0.649272253972181,\n",
       " 695: 1.204728812564379,\n",
       " 696: 0.5106956585202093,\n",
       " 697: 1.1535784798151034,\n",
       " 698: 0.38386187929278465,\n",
       " 699: 0.3025343278951766,\n",
       " 700: 0.6627261437458078,\n",
       " 701: 1.2200450133152057,\n",
       " 702: 1.1676081721865237,\n",
       " 703: 1.1996638192197195,\n",
       " 704: 1.4649665405112418,\n",
       " 705: 0.5931118561641763,\n",
       " 706: 0.6027304886774367,\n",
       " 707: 0.6926067097112595,\n",
       " 708: 0.5846643797692251,\n",
       " 709: 0.34517185685841445}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "euclid_dists[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "jf9twfLtWkLU"
   },
   "source": [
    "#### Indexing\n",
    "To take a closer look at an example of the reference indexing, we can call the ***index_dict*** function on the scaled testing feature data. Each key is ordered from 0-177, but the actual true row index of the dataset at each key index is different. The actual true row index of the randomized data corresponds to the values of these 177 keys. This is why I refer to it as a 'reference'. This can be seen below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "5ukCbvW_af8e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Siblings/Spouses Aboard</th>\n",
       "      <th>Parents/Children Aboard</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.031961</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.036598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.738783</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.050610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.295806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.830977</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.031230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.247081</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.569760</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.156150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.323909</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.539029</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.051505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.277812</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.050749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.431469</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>177 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass  Sex       Age  Siblings/Spouses Aboard  Parents/Children Aboard  \\\n",
       "405     0.5    0  0.031961                    0.125                      0.2   \n",
       "792     0.0    1  0.738783                    0.000                      0.0   \n",
       "303     0.0    0  0.000000                    0.125                      0.4   \n",
       "15      0.5    1  0.830977                    0.000                      0.0   \n",
       "430     1.0    0  0.247081                    0.000                      0.0   \n",
       "..      ...  ...       ...                      ...                      ...   \n",
       "60      0.0    1  0.569760                    0.000                      0.0   \n",
       "222     1.0    0  0.323909                    0.000                      0.0   \n",
       "569     0.0    0  0.539029                    0.000                      0.0   \n",
       "424     0.5    1  0.277812                    0.000                      0.0   \n",
       "106     1.0    0  0.431469                    0.000                      0.0   \n",
       "\n",
       "         Fare  \n",
       "405  0.036598  \n",
       "792  0.050610  \n",
       "303  0.295806  \n",
       "15   0.031230  \n",
       "430  0.013907  \n",
       "..        ...  \n",
       "60   0.156150  \n",
       "222  0.015412  \n",
       "569  0.051505  \n",
       "424  0.050749  \n",
       "106  0.015176  \n",
       "\n",
       "[177 rows x 6 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take note of the indexes of the testing data\n",
    "sc_test_feat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "q4eFD1IuWnl1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 405,\n",
       " 1: 792,\n",
       " 2: 303,\n",
       " 3: 15,\n",
       " 4: 430,\n",
       " 5: 673,\n",
       " 6: 803,\n",
       " 7: 363,\n",
       " 8: 445,\n",
       " 9: 710,\n",
       " 10: 336,\n",
       " 11: 341,\n",
       " 12: 865,\n",
       " 13: 787,\n",
       " 14: 776,\n",
       " 15: 163,\n",
       " 16: 554,\n",
       " 17: 800,\n",
       " 18: 328,\n",
       " 19: 156,\n",
       " 20: 592,\n",
       " 21: 251,\n",
       " 22: 231,\n",
       " 23: 433,\n",
       " 24: 3,\n",
       " 25: 89,\n",
       " 26: 143,\n",
       " 27: 364,\n",
       " 28: 255,\n",
       " 29: 48,\n",
       " 30: 745,\n",
       " 31: 346,\n",
       " 32: 530,\n",
       " 33: 764,\n",
       " 34: 356,\n",
       " 35: 699,\n",
       " 36: 58,\n",
       " 37: 693,\n",
       " 38: 688,\n",
       " 39: 493,\n",
       " 40: 815,\n",
       " 41: 283,\n",
       " 42: 659,\n",
       " 43: 526,\n",
       " 44: 635,\n",
       " 45: 37,\n",
       " 46: 826,\n",
       " 47: 11,\n",
       " 48: 199,\n",
       " 49: 647,\n",
       " 50: 628,\n",
       " 51: 331,\n",
       " 52: 46,\n",
       " 53: 71,\n",
       " 54: 183,\n",
       " 55: 263,\n",
       " 56: 817,\n",
       " 57: 168,\n",
       " 58: 278,\n",
       " 59: 419,\n",
       " 60: 721,\n",
       " 61: 506,\n",
       " 62: 683,\n",
       " 63: 40,\n",
       " 64: 80,\n",
       " 65: 33,\n",
       " 66: 450,\n",
       " 67: 132,\n",
       " 68: 695,\n",
       " 69: 120,\n",
       " 70: 261,\n",
       " 71: 31,\n",
       " 72: 718,\n",
       " 73: 681,\n",
       " 74: 398,\n",
       " 75: 833,\n",
       " 76: 886,\n",
       " 77: 114,\n",
       " 78: 472,\n",
       " 79: 846,\n",
       " 80: 437,\n",
       " 81: 503,\n",
       " 82: 420,\n",
       " 83: 864,\n",
       " 84: 788,\n",
       " 85: 373,\n",
       " 86: 246,\n",
       " 87: 259,\n",
       " 88: 485,\n",
       " 89: 842,\n",
       " 90: 332,\n",
       " 91: 860,\n",
       " 92: 784,\n",
       " 93: 142,\n",
       " 94: 870,\n",
       " 95: 527,\n",
       " 96: 126,\n",
       " 97: 759,\n",
       " 98: 816,\n",
       " 99: 733,\n",
       " 100: 544,\n",
       " 101: 417,\n",
       " 102: 480,\n",
       " 103: 240,\n",
       " 104: 92,\n",
       " 105: 557,\n",
       " 106: 667,\n",
       " 107: 547,\n",
       " 108: 622,\n",
       " 109: 863,\n",
       " 110: 277,\n",
       " 111: 634,\n",
       " 112: 786,\n",
       " 113: 377,\n",
       " 114: 742,\n",
       " 115: 72,\n",
       " 116: 571,\n",
       " 117: 545,\n",
       " 118: 111,\n",
       " 119: 308,\n",
       " 120: 565,\n",
       " 121: 732,\n",
       " 122: 0,\n",
       " 123: 845,\n",
       " 124: 349,\n",
       " 125: 619,\n",
       " 126: 497,\n",
       " 127: 42,\n",
       " 128: 821,\n",
       " 129: 670,\n",
       " 130: 484,\n",
       " 131: 26,\n",
       " 132: 100,\n",
       " 133: 810,\n",
       " 134: 27,\n",
       " 135: 481,\n",
       " 136: 157,\n",
       " 137: 791,\n",
       " 138: 579,\n",
       " 139: 383,\n",
       " 140: 402,\n",
       " 141: 455,\n",
       " 142: 511,\n",
       " 143: 572,\n",
       " 144: 611,\n",
       " 145: 633,\n",
       " 146: 850,\n",
       " 147: 98,\n",
       " 148: 648,\n",
       " 149: 117,\n",
       " 150: 805,\n",
       " 151: 705,\n",
       " 152: 680,\n",
       " 153: 686,\n",
       " 154: 65,\n",
       " 155: 589,\n",
       " 156: 290,\n",
       " 157: 152,\n",
       " 158: 41,\n",
       " 159: 76,\n",
       " 160: 198,\n",
       " 161: 591,\n",
       " 162: 546,\n",
       " 163: 436,\n",
       " 164: 139,\n",
       " 165: 429,\n",
       " 166: 190,\n",
       " 167: 181,\n",
       " 168: 367,\n",
       " 169: 362,\n",
       " 170: 515,\n",
       " 171: 179,\n",
       " 172: 60,\n",
       " 173: 222,\n",
       " 174: 569,\n",
       " 175: 424,\n",
       " 176: 106}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keys correspond to the ordered number of rows in the dataset.\n",
    "# Their associated values correspond to the actual true indexes seen above.\n",
    "# This structure allows the true indexing values to be accessed easily within the for loops of functions\n",
    "\n",
    "test_inds = index_dict(sc_test_feat)\n",
    "test_inds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ft3UfYJSEDxu"
   },
   "source": [
    "## 2.3 K-NN Predictions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Hg8yd2Xdu0V"
   },
   "source": [
    "Extracting the results of the K-NN model using the ***knn_fit*** function previously defined:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "WbAtpnlL5vhJ"
   },
   "outputs": [],
   "source": [
    "knn_results = knn_fit(sc_train_feat, sc_test_feat, train_labels, test_labels, euclid_dists, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IurdTIN2_2Z_"
   },
   "source": [
    "The results are a dictionary object containing the actual target label and the predicted target label for each row of the testing data. Note that in Google Colab, the dictionary keys (strings here) are **ordered** as default. All row indexes do correspond to the true row index from the randomized test feature data, but they just appear ordered here.\n",
    "\n",
    "(In Jupyter notebook the keys will appear as they are added and will not be ordered, meaning the order of keys would correspond direclty to the order of rows in the randomized data, i.e. the first row in the dictionary would be 'Test Row ...[first true index of feature data ]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "txiuMKsje48U"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Test row 405': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 792': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 303': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 15': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 430': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 673': {'Actual': 0, 'Prediction': 1},\n",
       " 'Test row 803': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 363': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 445': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 710': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 336': {'Actual': 1, 'Prediction': 0},\n",
       " 'Test row 341': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 865': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 787': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 776': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 163': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 554': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 800': {'Actual': 1, 'Prediction': 0},\n",
       " 'Test row 328': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 156': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 592': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 251': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 231': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 433': {'Actual': 0, 'Prediction': 1},\n",
       " 'Test row 3': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 89': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 143': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 364': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 255': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 48': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 745': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 346': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 530': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 764': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 356': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 699': {'Actual': 0, 'Prediction': 1},\n",
       " 'Test row 58': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 693': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 688': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 493': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 815': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 283': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 659': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 526': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 635': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 37': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 826': {'Actual': 1, 'Prediction': 0},\n",
       " 'Test row 11': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 199': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 647': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 628': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 331': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 46': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 71': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 183': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 263': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 817': {'Actual': 1, 'Prediction': 0},\n",
       " 'Test row 168': {'Actual': 0, 'Prediction': 1},\n",
       " 'Test row 278': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 419': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 721': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 506': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 683': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 40': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 80': {'Actual': 1, 'Prediction': 0},\n",
       " 'Test row 33': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 450': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 132': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 695': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 120': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 261': {'Actual': 0, 'Prediction': 1},\n",
       " 'Test row 31': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 718': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 681': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 398': {'Actual': 1, 'Prediction': 0},\n",
       " 'Test row 833': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 886': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 114': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 472': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 846': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 437': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 503': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 420': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 864': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 788': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 373': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 246': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 259': {'Actual': 1, 'Prediction': 0},\n",
       " 'Test row 485': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 842': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 332': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 860': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 784': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 142': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 870': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 527': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 126': {'Actual': 1, 'Prediction': 0},\n",
       " 'Test row 759': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 816': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 733': {'Actual': 1, 'Prediction': 0},\n",
       " 'Test row 544': {'Actual': 1, 'Prediction': 0},\n",
       " 'Test row 417': {'Actual': 0, 'Prediction': 1},\n",
       " 'Test row 480': {'Actual': 1, 'Prediction': 0},\n",
       " 'Test row 240': {'Actual': 1, 'Prediction': 0},\n",
       " 'Test row 92': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 557': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 667': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 547': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 622': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 863': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 277': {'Actual': 1, 'Prediction': 0},\n",
       " 'Test row 634': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 786': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 377': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 742': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 72': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 571': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 545': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 111': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 308': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 565': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 732': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 0': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 845': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 349': {'Actual': 0, 'Prediction': 1},\n",
       " 'Test row 619': {'Actual': 1, 'Prediction': 0},\n",
       " 'Test row 497': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 42': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 821': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 670': {'Actual': 1, 'Prediction': 0},\n",
       " 'Test row 484': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 26': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 100': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 810': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 27': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 481': {'Actual': 1, 'Prediction': 0},\n",
       " 'Test row 157': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 791': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 579': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 383': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 402': {'Actual': 0, 'Prediction': 1},\n",
       " 'Test row 455': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 511': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 572': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 611': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 633': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 850': {'Actual': 0, 'Prediction': 1},\n",
       " 'Test row 98': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 648': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 117': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 805': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 705': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 680': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 686': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 65': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 589': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 290': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 152': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 41': {'Actual': 0, 'Prediction': 1},\n",
       " 'Test row 76': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 198': {'Actual': 0, 'Prediction': 1},\n",
       " 'Test row 591': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 546': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 436': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 139': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 429': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 190': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 181': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 367': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 362': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 515': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 179': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 60': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 222': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 569': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 424': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 106': {'Actual': 1, 'Prediction': 0}}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_results  # dictionaries odered by default "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KJx2LvOLECJJ"
   },
   "source": [
    "## 2.4 Evaluating the K-NN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fVnvh5YDHWQv"
   },
   "source": [
    "Before computing the testing accuracy, we can calculate the baseline accuracy that can be achieved with this data. If we tally both classes (survived or not) and divide the max tally by the total number of classes, we can identify the minimum accuracy that can be achieved. In my randomized data, the baseline accuracy was 0.58192."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "x2Qf9M96FxKc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.615819209039548"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_common = max([test_labels[test_labels==1].count(),test_labels[test_labels==0].count()])\n",
    "\n",
    "baseline_acc = most_common/len(test_features)\n",
    "\n",
    "baseline_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rReI2GjpCYja"
   },
   "source": [
    "Evaluating the actual testing accuracy of this K-NN model using the ***evaluate_knn*** function previosuly defined.In my testing of the model, the model achieved an accuracy of 0.8248, which is a reasonably good level of accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "ltPkLYQoC_a9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8418079096045198"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_knn(knn_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UmvSn4OwDxa_"
   },
   "source": [
    "Plotting the confusion matrix using the ***confusion_matrix*** function previously defined:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "CE4qF7QaC_ed"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_94a1d_row0_col0, #T_94a1d_row1_col1 {\n",
       "  background-color: #08306b;\n",
       "  color: #f1f1f1;\n",
       "  font-size: 35px;\n",
       "}\n",
       "#T_94a1d_row0_col1, #T_94a1d_row1_col0 {\n",
       "  background-color: #f7fbff;\n",
       "  color: #000000;\n",
       "  font-size: 35px;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_94a1d\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Predicted</th>\n",
       "      <th id=\"T_94a1d_level0_col0\" class=\"col_heading level0 col0\" >0</th>\n",
       "      <th id=\"T_94a1d_level0_col1\" class=\"col_heading level0 col1\" >1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Actual</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_94a1d_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_94a1d_row0_col0\" class=\"data row0 col0\" >98</td>\n",
       "      <td id=\"T_94a1d_row0_col1\" class=\"data row0 col1\" >11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_94a1d_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_94a1d_row1_col0\" class=\"data row1 col0\" >17</td>\n",
       "      <td id=\"T_94a1d_row1_col1\" class=\"data row1 col1\" >51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x187201fe130>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(knn_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAI9NCLlR5k3"
   },
   "source": [
    "The 177 cases from the testing feature data are represented in this confusion matrix. The rows correspond to the actual target label for these cases, while columns correspond to the predicted target label. A value of 0 means the person did not survive, while a value of 1 means they did survive. \n",
    "\n",
    "***Moving across the matrix:***\n",
    "\n",
    "The first cell of the matrix [0,0] represents the number of cases the model predicted as 'not survived' when the actual target label was 'not survived'. This corresponds to a correct prediction. This number is the highest of all cells in the matrix, highlighting the model's superior ability to accurately predict those who did not survive.\n",
    "\n",
    "The next cell of the matrix [0,1] represents the number of cases the model predicted as 'survived' when the actual target label was 'not survived'. This corresponds to an incorrect prediction.\n",
    "\n",
    "The next cell of the matrix [1,0] represents the number of cases the model predicted as 'not survived' when the actual target label was 'survived'. This corresponds to an incorrect prediction. This number is the largest of both incorrect predictions in the matrix, meaning when the model was incorrect in its prediction, it was more likely predicting those who 'survived' as 'not survived'.\n",
    "\n",
    "The last cell of the matrix [1,1] represents the number of cases the model predicted as 'survived' when the actual target label was 'survived'. This corresponds to a correct prediction. This number is significantly less than the other correctly predicted cases in the matrix [0,0], again highlighting the fact that the model was more capable of predicting those who did not survive.\n",
    "\n",
    "**Note: values may differ across various test runs of the code.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VTcjCv_lSB3r"
   },
   "source": [
    "# Part 3 - Hyperparameters search \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XZn-sI14QbZe"
   },
   "source": [
    "Testing possible k values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "iQybOEzYSYdq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.824859 testing accuracy with k = 1\n",
      "0.830508 testing accuracy with k = 3\n",
      "0.841808 testing accuracy with k = 5\n",
      "0.807910 testing accuracy with k = 7\n",
      "0.824859 testing accuracy with k = 9\n",
      "0.813559 testing accuracy with k = 11\n"
     ]
    }
   ],
   "source": [
    "hyperpar_res = []\n",
    "possible_k = [1, 3, 5, 7, 9, 11]\n",
    "\n",
    "for kval in possible_k:\n",
    "    \n",
    "    k_result = knn_fit(sc_train_feat, sc_test_feat, train_labels, test_labels, euclid_dists, k=kval)\n",
    "    \n",
    "    hyperpar_res.append(k_result)\n",
    "\n",
    "for d in range(len(hyperpar_res)):\n",
    "    print('%f testing accuracy with k = %i' % (evaluate_knn(hyperpar_res[d]), possible_k[d]))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hYhbpIdzXtSz"
   },
   "source": [
    "Confusion matrix of results generated from K-NN with k = 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "W_EX3Z0YXIkc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_50c66_row0_col0, #T_50c66_row1_col1 {\n",
       "  background-color: #08306b;\n",
       "  color: #f1f1f1;\n",
       "  font-size: 35px;\n",
       "}\n",
       "#T_50c66_row0_col1, #T_50c66_row1_col0 {\n",
       "  background-color: #f7fbff;\n",
       "  color: #000000;\n",
       "  font-size: 35px;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_50c66\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Predicted</th>\n",
       "      <th id=\"T_50c66_level0_col0\" class=\"col_heading level0 col0\" >0</th>\n",
       "      <th id=\"T_50c66_level0_col1\" class=\"col_heading level0 col1\" >1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Actual</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_50c66_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_50c66_row0_col0\" class=\"data row0 col0\" >96</td>\n",
       "      <td id=\"T_50c66_row0_col1\" class=\"data row0 col1\" >13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_50c66_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_50c66_row1_col0\" class=\"data row1 col0\" >21</td>\n",
       "      <td id=\"T_50c66_row1_col1\" class=\"data row1 col1\" >47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x18721ff6610>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(hyperpar_res[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5lo_ThvzX0SO"
   },
   "source": [
    "Confusion matrix of results generated from K-NN with k = 11:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "C3wWrtWvXLns"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_a44b0_row0_col0, #T_a44b0_row1_col1 {\n",
       "  background-color: #08306b;\n",
       "  color: #f1f1f1;\n",
       "  font-size: 35px;\n",
       "}\n",
       "#T_a44b0_row0_col1, #T_a44b0_row1_col0 {\n",
       "  background-color: #f7fbff;\n",
       "  color: #000000;\n",
       "  font-size: 35px;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_a44b0\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Predicted</th>\n",
       "      <th id=\"T_a44b0_level0_col0\" class=\"col_heading level0 col0\" >0</th>\n",
       "      <th id=\"T_a44b0_level0_col1\" class=\"col_heading level0 col1\" >1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Actual</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_a44b0_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_a44b0_row0_col0\" class=\"data row0 col0\" >98</td>\n",
       "      <td id=\"T_a44b0_row0_col1\" class=\"data row0 col1\" >11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a44b0_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_a44b0_row1_col0\" class=\"data row1 col0\" >22</td>\n",
       "      <td id=\"T_a44b0_row1_col1\" class=\"data row1 col1\" >46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x187226b6a60>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(hyperpar_res[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QK_3BeveSey-"
   },
   "source": [
    "In my particular testing of the model, the best accuracy value was achieved with a k value of 5 or 11 (tied value). From observing both confusion matrices, the performance of each is almost identical. In this case I would choose the lower k value of 5, as it achieves the same accuracy as k = 11. A k value of 5 appears to be large enough so as to avoid the influence of potential outliers that may present nearer to the target point. In addition, a k value of 5 is small enough so that it is not incorporating too many 'nearest' points, especially those that may actually be closer to other targets. \n",
    "\n",
    "In this test run, each of the k values (excluding 1) appear to perform quite similarly, meaning the optimal value of k in this case is only marginally improving on the other k values. Despite generating an accuracy of 0.774, it is clear that a k value of 1 is the worst choice of k, as it is just too small and is only considering one nearest neighbour, which is not enough to base an accurate prediction on. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-FMED-C_RZzq"
   },
   "source": [
    "# Part 4 - Weighted k-NN \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5vSoOpi6YD71"
   },
   "source": [
    "Function for performing weighted k-NN. The distance weighted metric in this case is the inverse distance squared.\n",
    "\n",
    "As we are dealing with a binary classification problem (0 or 1 label), we can just sum the weighted distances for each target label individually. The target label with the largest sum of weights will be the overall precition for a target row of testing data.\n",
    "\n",
    "Also, as it is a weighted k-NN being performed, I have included an option for using 'all' points in the dataset instead of just k nearest neighbours. Points that are nearer to the target will be weighted the highest, while those further away will have very small weights, and little to no influence on the predicted outcome. Therefore, technically all points can be involved.\n",
    "\n",
    "***Accounting for 0 distance:***\n",
    "\n",
    "To account for two points potentially having 0 distance and to avoid a division by zero error, I have added a miniscule value (1e-7) onto the distance squared value within the weight computation. This will prevent any value of zero from occuring and thus there should be no division by zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "FwtZr4HURgfI"
   },
   "outputs": [],
   "source": [
    "# weighted_knn function\n",
    "# Similar to knn_fit function from before\n",
    "# Computes the predicted results from a dictionary of Euclidian distances.\n",
    "# Calculates the inverse Euclidian distance squared.\n",
    "# Sums these weighted distances for both target labels.\n",
    "# Label corresponding to the maximum sum of weights = the predicted target label.\n",
    "# Returns a dictionary containing the actual and predicted target label of each row.\n",
    "# Default k set to 5, but can be changed and also set to 'all'.\n",
    "\n",
    "def weighted_knn(train_feat, test_feat, train_labels, test_labels, euclid_dists, k=5):\n",
    "    \n",
    "    train_ind = index_dict(train_feat)\n",
    "    test_ind = index_dict(test_feat)\n",
    "    \n",
    "    w_knn = {}\n",
    "\n",
    "    for i in range(len(euclid_dists)):\n",
    "\n",
    "        # for summing the weighted distances of each target label\n",
    "        surv_sum = 0\n",
    "        deceased_sum = 0\n",
    "    \n",
    "        w_knn['Test row ' + str(test_ind[i])] = {'Actual':test_labels[test_ind[i]]}\n",
    "\n",
    "        # if all points are selected instead of just k nearest\n",
    "        if k == 'all':\n",
    "            k_nearest = euclid_dists[i].values()\n",
    "        else:\n",
    "            k_nearest = sorted(euclid_dists[i].values())[:k]\n",
    "        \n",
    "        for key, value in euclid_dists[i].items():\n",
    "    \n",
    "            if value in k_nearest:\n",
    "\n",
    "                index = train_ind[key]\n",
    "\n",
    "                # calculate the inverse weighted square + 1e-7\n",
    "                w = 1/(value**2 + 0.0000001)         \n",
    "\n",
    "                # if label is 1, add to survived sum of weights\n",
    "                # otherwise add to deceased\n",
    "                if train_labels[index] == 1:\n",
    "                    surv_sum += w\n",
    "                else:\n",
    "                    deceased_sum += w\n",
    "\n",
    "        # same as knn_fit\n",
    "        if surv_sum > deceased_sum:\n",
    "            w_knn['Test row ' + str(test_ind[i])]['Prediction'] = 1\n",
    "        else:\n",
    "            w_knn['Test row ' + str(test_ind[i])]['Prediction'] = 0\n",
    "            \n",
    "    return w_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "cdqADEDldtnw"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Test row 405': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 792': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 303': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 15': {'Actual': 1, 'Prediction': 0},\n",
       " 'Test row 430': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 673': {'Actual': 0, 'Prediction': 1},\n",
       " 'Test row 803': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 363': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 445': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 710': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 336': {'Actual': 1, 'Prediction': 0},\n",
       " 'Test row 341': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 865': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 787': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 776': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 163': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 554': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 800': {'Actual': 1, 'Prediction': 0},\n",
       " 'Test row 328': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 156': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 592': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 251': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 231': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 433': {'Actual': 0, 'Prediction': 1},\n",
       " 'Test row 3': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 89': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 143': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 364': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 255': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 48': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 745': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 346': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 530': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 764': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 356': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 699': {'Actual': 0, 'Prediction': 1},\n",
       " 'Test row 58': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 693': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 688': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 493': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 815': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 283': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 659': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 526': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 635': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 37': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 826': {'Actual': 1, 'Prediction': 0},\n",
       " 'Test row 11': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 199': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 647': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 628': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 331': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 46': {'Actual': 1, 'Prediction': 0},\n",
       " 'Test row 71': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 183': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 263': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 817': {'Actual': 1, 'Prediction': 0},\n",
       " 'Test row 168': {'Actual': 0, 'Prediction': 1},\n",
       " 'Test row 278': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 419': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 721': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 506': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 683': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 40': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 80': {'Actual': 1, 'Prediction': 0},\n",
       " 'Test row 33': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 450': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 132': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 695': {'Actual': 0, 'Prediction': 1},\n",
       " 'Test row 120': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 261': {'Actual': 0, 'Prediction': 1},\n",
       " 'Test row 31': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 718': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 681': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 398': {'Actual': 1, 'Prediction': 0},\n",
       " 'Test row 833': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 886': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 114': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 472': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 846': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 437': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 503': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 420': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 864': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 788': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 373': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 246': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 259': {'Actual': 1, 'Prediction': 0},\n",
       " 'Test row 485': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 842': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 332': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 860': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 784': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 142': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 870': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 527': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 126': {'Actual': 1, 'Prediction': 0},\n",
       " 'Test row 759': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 816': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 733': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 544': {'Actual': 1, 'Prediction': 0},\n",
       " 'Test row 417': {'Actual': 0, 'Prediction': 1},\n",
       " 'Test row 480': {'Actual': 1, 'Prediction': 0},\n",
       " 'Test row 240': {'Actual': 1, 'Prediction': 0},\n",
       " 'Test row 92': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 557': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 667': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 547': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 622': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 863': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 277': {'Actual': 1, 'Prediction': 0},\n",
       " 'Test row 634': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 786': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 377': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 742': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 72': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 571': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 545': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 111': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 308': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 565': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 732': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 0': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 845': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 349': {'Actual': 0, 'Prediction': 1},\n",
       " 'Test row 619': {'Actual': 1, 'Prediction': 0},\n",
       " 'Test row 497': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 42': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 821': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 670': {'Actual': 1, 'Prediction': 0},\n",
       " 'Test row 484': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 26': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 100': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 810': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 27': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 481': {'Actual': 1, 'Prediction': 0},\n",
       " 'Test row 157': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 791': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 579': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 383': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 402': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 455': {'Actual': 1, 'Prediction': 0},\n",
       " 'Test row 511': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 572': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 611': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 633': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 850': {'Actual': 0, 'Prediction': 1},\n",
       " 'Test row 98': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 648': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 117': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 805': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 705': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 680': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 686': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 65': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 589': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 290': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 152': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 41': {'Actual': 0, 'Prediction': 1},\n",
       " 'Test row 76': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 198': {'Actual': 0, 'Prediction': 1},\n",
       " 'Test row 591': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 546': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 436': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 139': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 429': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 190': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 181': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 367': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 362': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 515': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 179': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 60': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 222': {'Actual': 0, 'Prediction': 0},\n",
       " 'Test row 569': {'Actual': 1, 'Prediction': 0},\n",
       " 'Test row 424': {'Actual': 1, 'Prediction': 1},\n",
       " 'Test row 106': {'Actual': 1, 'Prediction': 0}}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_knn = weighted_knn(sc_train_feat, sc_test_feat, train_labels, test_labels, euclid_dists, k=5)\n",
    "\n",
    "# similar output as before\n",
    "w_knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fNE2qVNSd_Ga"
   },
   "source": [
    "Evaluating the accuracy of weighted k-NN with different values for k, and comapring these values to the accuracy achieved with the original k-NN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "k_GIq_4ADI8l"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.824859 Weighted testing accuracy with k = 1\n",
      "0.824859 Original testing accuracy with k = 1\n",
      "\n",
      "0.813559 Weighted testing accuracy with k = 3\n",
      "0.830508 Original testing accuracy with k = 3\n",
      "\n",
      "0.824859 Weighted testing accuracy with k = 5\n",
      "0.841808 Original testing accuracy with k = 5\n",
      "\n",
      "0.824859 Weighted testing accuracy with k = 7\n",
      "0.807910 Original testing accuracy with k = 7\n",
      "\n",
      "0.836158 Weighted testing accuracy with k = 9\n",
      "0.824859 Original testing accuracy with k = 9\n",
      "\n",
      "0.830508 Weighted testing accuracy with k = 11\n",
      "0.813559 Original testing accuracy with k = 11\n",
      "\n",
      "0.836158 Weighted testing accuracy with k = 13\n",
      "0.813559 Original testing accuracy with k = 13\n",
      "\n",
      "0.836158 Weighted testing accuracy with k = 15\n",
      "0.790960 Original testing accuracy with k = 15\n",
      "\n",
      "0.807910 Weighted testing accuracy with k = all\n"
     ]
    }
   ],
   "source": [
    "weight_res = []\n",
    "original_res = []\n",
    "possible_k = [1, 3, 5, 7, 9, 11, 13, 15] # try some new k values\n",
    "\n",
    "for k in possible_k:\n",
    "    \n",
    "    # compute original and weighted results\n",
    "    wknn_result = weighted_knn(sc_train_feat, sc_test_feat, train_labels, test_labels, euclid_dists, k=k)\n",
    "    knn_result = knn_fit(sc_train_feat, sc_test_feat, train_labels, test_labels, euclid_dists, k=k)\n",
    "    \n",
    "    weight_res.append(wknn_result)\n",
    "    original_res.append(knn_result)\n",
    "\n",
    "# evaluate both original and testing accuracy \n",
    "for d in range(len(weight_res)):\n",
    "    print('%f Weighted testing accuracy with k = %s' % (evaluate_knn(weight_res[d]), str(possible_k[d])))\n",
    "    print('%f Original testing accuracy with k = %i' % (evaluate_knn(original_res[d]), possible_k[d]))\n",
    "    print()\n",
    "\n",
    "# testing all points as k in the weighted model\n",
    "wknn_all = weighted_knn(sc_train_feat, sc_test_feat, train_labels, test_labels, euclid_dists, k='all')\n",
    "print('%f Weighted testing accuracy with k = all' % (evaluate_knn(wknn_all)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RRAXH_EDRlm8"
   },
   "source": [
    "In my test run of the model:\n",
    "\n",
    "The weighted k-KNN model does not outperform the original model when both have k = 5. However, when k=11 the weighted k-NN model outperforms the original model at k = 7, 9, 11, 13 and 15, suggesting that the weighted model performs slightly better than the original at higher values of k. \n",
    "\n",
    "The maximum accuracy was achieved with the weighted model, with a value of 0.830508 at k = 11, 13 and 15. The testing accuracy evidently plateaud across these values, but could maybe be slighlty improved upon at higher values.\n",
    "\n",
    "Interestingly, when incorporating all values in the dataset as k, the accuracy decreases to 0.813559. \n",
    "\n",
    "***Again note these results may differ across different test runs due to randomization of the data at the start. The model does not take long to run so one can run it again if they please and check other possible results.***"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CS6405_A1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
